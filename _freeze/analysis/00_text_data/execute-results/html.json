{
  "hash": "6cc6fd0cfe496eb55168896d7498a64a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Text Data Sources\"\nauthor: \"Luisa M. Mimmi\"\ndate: \"Last run: 2024-05-29\"\nlang: en\neditor: source\nengine: knitr\n## ------  general Output Options\nexecute:     \n  eval: false    # actually run? \n  echo: true     #  include source code in output\n  warning: false  #  include warning code in output\n  error: false    #  include error code in output\n  output: false   # include output code in output (CHG in BLOCKS)\n  # include: false   # R still runs but code and results DON\"T appear in output  \n  cache: false # normalmnte false\ntoc: true\nfig-cap-location: top\ntbl-cap-location: top\nformat:\n  html:\n    # theme: flatly #spacelab\n    code-fold: false # redundant bc echo false \n    toc-depth: 3\n    toc_float: true\n    toc-location: left\n    toc-title: Outline\n    embed-resources: true # external dependencies embedded (Not in ..._files/)\n  # pdf:\n  #   toc-depth: 2\n  #   toc-title: Indice\n  #   highlight-style: github\n  #   #lang: it\n  #   embed-resources: true # external dependencies embedded (Not in ..._files/)\nformat-links: false\nbibliography: ../bib/slogan.bib\n---\n\n\n<i class=\"fa fa-refresh\" style=\"color: firebrick\"></i> Work in progress\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Pckgs -------------------------------------\nif (!require (\"pacman\")) (install.packages(\"pacman\"))\np_load(tidyverse, \n       janitor, \n       here,\n       repurrrsive, # examples of recursive lists\n       listviewer, # provides an interactive method for viewing the structure of a list.\n       httr, jsonlite, XML,xml2, \n       oai, # R client to work with OAI-PMH \n       citr,\n       fs)\n```\n:::\n\n\n<!-- #### setup -->\n\n<!-- ```{r setup_inp, echo=FALSE} -->\n<!-- # Pckgs ------------------------------------- -->\n<!-- if (!require (\"pacman\")) (install.packages(\"pacman\")) -->\n<!-- #p_install_gh(\"luisDVA/annotater\") -->\n<!-- #p_install_gh(\"HumanitiesDataAnalysis/hathidy\") -->\n<!-- # devtools::install_github(\"HumanitiesDataAnalysis/HumanitiesDataAnalysis\")  -->\n<!-- pacman::p_load(here, -->\n<!--        annotater, -->\n<!--        tidyverse,  -->\n<!--        skimr, -->\n<!--        scales, -->\n<!--        httr,  -->\n<!--        citr, -->\n<!--        paint,  -->\n<!--        DT, # an R interface to the JavaScript library DataTables -->\n<!--        # jsonlite,  -->\n<!--        # XML,  -->\n<!--        # xml2,  -->\n<!--        # oai, # R client to work with OAI-PMH  -->\n<!--        splitstackshape #Stack and Reshape Datasets After Splitting Concatenated Values -->\n<!--        ) -->\n\n<!-- pacman::p_load( -->\n<!--   tm, # Text Mining Package -->\n<!--   tidytext, # Text Mining using 'dplyr', 'ggplot2', and Other Tidy Tools -->\n<!--   widyr, # pairwise ????   -->\n<!--   ggraph, -->\n<!--   igraph, -->\n<!--   sjmisc, # Data and Variable Transformation Functions -->\n<!--   ggraph, # An Implementation of Grammar of Graphics for Graphs and Networks -->\n<!--   widyr, # Widen, Process, then Re-Tidy Data -->\n<!--   SnowballC, # Snowball Stemmers Based on the C 'libstemmer' UTF-8 Library -->\n<!--   #HumanitiesDataAnalysis, # Data and Code for Teaching Humanities Data Analysis -->\n<!--   sentencepiece # Text Tokenization using Byte Pair Encoding and Unigram Modelling -->\n<!-- ) -->\n\n<!-- # Function(s) ------------------------------------- -->\n\n<!-- # Data ------------------------------------- -->\n\n<!-- ``` -->\n\n\n### ----------------------------------------------------------------------------\n\n# Data sources\n\n# WB Projects & Operations\n**World Bank Projects & Operations**: [Data Catalog](https://datacatalog.worldbank.org/search/dataset/0037800> <https://datacatalog.worldbank.org/search/dataset/0037800/World-Bank-Projects---Operations)\nhttps://projects.worldbank.org/en/projects-operations/project-search \n\n-   Accessibility Classification: **public** under [Creative Commons Attribution 4.0](https://datacatalog.worldbank.org/public-licenses?fragment=cc)\n\n- esempio <https://datacatalog.worldbank.org/search/dataset/0037800> <https://datacatalog.worldbank.org/search/dataset/0037800/World-Bank-Projects---Operations>\n\n \n## Raw data\nI retrieved manually ALL WB projects approved *between FY 1973 and 2023 (last FY incomplete)* on 09/22/2022 (WDRs go from 1978-2022)\nusing this [example url FY 1978/79](https://projects.worldbank.org/en/projects-operations/projects-list?str_fiscalyear=1979&end_fiscalyear=1979&os=0) and saved individual `.xlsx` files in `data/raw_data/`\n\n<!-- EXE  -->\n<!-- https://projects.worldbank.org/en/projects-operations/projects-list?str_fiscalyear=1979&end_fiscalyear=1979&os=0 -->\n<!-- https://projects.worldbank.org/en/projects-operations/projects-list?str_fiscalyear=2023&end_fiscalyear=2023&os=0 -->\n\n## Ingest Projects data\n\nI retrieved manually ALL WB projects approved *between FY 1973 and 2023 (last FY incomplete)* on 09/22/2022 (WDRs go from 1978-2022)\nusing this [example url](https://projects.worldbank.org/en/projects-operations/projects-list?str_fiscalyear=1979&end_fiscalyear=1979&os=0) and saved individual `.xlsx` files in `data/raw_data/`\n\n+ note the manual download is limited to # = 500\n\n### --- Load all `.xlsx` files separately \n<!-- Following https://martinctc.github.io/blog/vignette-write-and-read-multiple-excel-files-with-purrr/ -->\n\n\n\n\n\n### --- Save objs in folder as `.Rds` files separately \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n### ---------------------------------------------------------------------------\n \n# World Development Reports (WRDs)\n\n-   DATA <https://datacatalog.worldbank.org/search/dataset/0037800>\n-   INSTRUCTIONS <https://documents.worldbank.org/en/publication/documents-reports/api>\n-   Following: [@kaye_ella_2019; @robinson_words_2017; @robinson_1_2022]\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function(s) -------------------------------------\nsource(here::here (\"R\", \"f_scrape_WB-OKR.R\") )\nsource(here::here (\"R\", \"turn_list_to_tibble.R\") )\n```\n:::\n\n\n\n## Raw data\n\n## OAI-PMH  \n\n**OAI-PMH** (Open Archives Initiative Protocol for Metadata Harvest-ing) services, a protocol developed by the Open Archives Initiative (https://en.wikipedia.org/wiki/Open_Archives_Initiative). OAI-PMH uses XML data format transported over HTTP.\n\n+ packg: Package [`oai`](https://docs.ropensci.org/oai/) is built on xml2 and httr. \n+ paging: OAI-PMH uses (optionally) `resumptionTokens`, with an optional expiration date. These tokens can be used to continue on to the next chunk of data, if the first request did not get to the end.\n\n## 1. World Bank list of World Development Reports\nGenreal OKR link [https://openknowledge.worldbank.org/search?spc.page=1&query=%20&scope=3d9bbbf6-c007-5043-b655-04d8a1cfbfb2](https://openknowledge.worldbank.org/search?spc.page=1&query=%20&scope=3d9bbbf6-c007-5043-b655-04d8a1cfbfb2)\n\nhttps://openknowledge.worldbank.org/entities/publication/5e5ac9f1-71ee-4734-825e-60966658395f\n2023 | key takeaways | https://openknowledge.worldbank.org/server/api/core/bitstreams/54de9b54-dc23-43da-9a88-fe94dd5a3c24/content\n\nhttps://openknowledge.worldbank.org/server/api/core/bitstreams/e1e22749-80c3-50ea-b7e1-8bc332d0c2ff/content\n\n + **World Development Report (WDR)**;  \n   + (in 2022) https://openknowledge.worldbank.org/handle/10986/2124\n   + (in 2024) https://openknowledge.worldbank.org/collections/3d9bbbf6-c007-5043-b655-04d8a1cfbfb2?spc.sf=dc.date.issued&spc.sd=DESC \n   + (in 2024) https://openknowledge.worldbank.org/collections/3d9bbbf6-c007-5043-b655-04d8a1cfbfb2?spc.sf=dc.date.issued&spc.sd=DESC&f.supportedlanguage=en,equals&spc.page=1&spc.rpp=100\n\n\n\n# >>>>>> QUI <<<<<<<<<<<<<<<<<< \n### ---------------------------------------------------------------------------\n\n \n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"rvest\")\nlibrary(rvest)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlink2023 <- \"https://openknowledge.worldbank.org/entities/publication/5e5ac9f1-71ee-4734-825e-60966658395f/full\"\nWDR2023 <- read_html(link2023)\n\nWDR2023  %>%\n  html_elements(xpath = \"\")\n```\n:::\n\n\n \n\n## 1. World Bank list of World Development Reports\n\nHere I want to extract documents metadata from WBG OKR repository. \n\nWhich metadata:\n  +  collections: \"Books\"                    https://openknowledge.worldbank.org/handle/10986/4\n    + sub-collections: \"Corporate Flagships\" https://openknowledge.worldbank.org/handle/10986/2123\n      + **World Development Report (WDR)**;  https://openknowledge.worldbank.org/handle/10986/2124\n      https://openknowledge.worldbank.org/collections/3d9bbbf6-c007-5043-b655-04d8a1cfbfb2?spc.sf=dc.date.issued&spc.sd=DESC \n      \n      + Global Economic Prospects (GEP), \n      + Doing Business (DB), and \n      + Poverty and Shared Prosperity (PSP).  \n      + ...\n\nI can search adding a keyword:           \n      + World Development Report (WDR);\n        + Keyword = _\"economic development\"_    \n... the url would become: `https://openknowledge.worldbank.org/handle/10986/2124/discover?filtertype=subject&filter_relational_operator=equals&filter=economic+development`\n \n# >>>>>> QUI <<<<<<<<<<<<<<<<<< \n### API response  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# DATA https://datacatalog.worldbank.org/search/dataset/0037800 \n# INSTRUCTIONS https://documents.worldbank.org/en/publication/documents-reports/api\n\n# VARIABLES ----------------------------------------------\n# base url for query\nbase <- \"https://openknowledge.worldbank.org/oai/request?verb=ListRecords&metadataPrefix=oai_dc&set=col_10986_\"\n# base url with resumption token\nbase0 <- \"https://openknowledge.worldbank.org/oai/request?verb=ListRecords&resumptionToken=oai_dc///col_10986_\"\n \nn <- 45 \nsubid <-   2124 # WRD \n\ntemp_url <- paste0(base, subid)\n\n# response <- httr::GET(temp_url) # xml_document\n# response <- httr::content(response, as=\"parsed\")\nresponse <- xml2::read_xml(x = temp_url, encoding = \"\",\n                           options = \"NOBLANKS\") # remove blank nodes\nclass(response)\n \n# Parse a url into its component pieces.\nxml2::xml_name(response) # [1] \"OAI-PMH\"\nxml2::xml_name(xml_children(response)) # [1] \"responseDate\" \"request\"  \"ListRecords\" \n\n# print the full path directory:\nresponse %>% xml_find_all( '//*') %>% xml_path()\n\n# check length of id\n#======# DON'T KNOW HOW SHE NEW THE NAME #======# \n# \"/*/*[3]/*[1]/*[2]/oai_dc:dc/dc:identifier[1]\"  \nr_id <-  xml2::xml_find_all(response, \".//d1:identifier\") %>% xml_text()\nl <- length(r_id)\nprint(paste(\"length of total list:\", l))\n\n# #======#  check length of subject ???  #======# \n# \"/*/*[3]/*[1]/*[2]/oai_dc:dc/dc:subject[216]\" \nr_subject <-  xml2::xml_find_all(response, \".//d1:subject\") %>% xml_text() # empty \nr_subject <-  xml2::xml_find_all(response, \".//subject\") %>% xml_text() # empty \n\n\n# START NAVIGATION\nr_root <- xml2::xml_root(response )   # Returns root node\nr_root\nr_cdr <- xml2::xml_children(response )   # Access the children nodes\nr_cdr\nstr(r_cdr)\n\n# all records as a list of lists \nr_cdr_l <- xml2::as_list(r_cdr)\nstr(r_cdr_l)\n# only the info in record (l1-of - l45)\nr_cdr_l_records <-  r_cdr_l[3]\n\n# only records as a list of 45 \nrecords <-  r_cdr_l_records[[1]] \nrecords[[1]][[\"metadata\"]][[\"dc\"]][[\"subject[1]\"]]\n\n\n# name the records \nnames(records) <- paste0 (\"WRD_\", 1:length(records))\nrecords_names <- c(names(records))\nclass(records_names)\n```\n:::\n\n\n### Parsing xml ONE INDICATOR AT A TIME (header)\n\n#### ... (form header) identifier\n\n::: {.cell}\n\n```{.r .cell-code}\n# # # identifier of record 1 \n# # records[[\"WRD_1\"]][[\"header\"]][[\"identifier\"]]\n# # # identifier of record 2 \n# # records[[\"WRD_2\"]][[\"header\"]][[\"identifier\"]]\n# \n# # all identifier \n# \n# # 1) Prepare empty vectors \n# id_l <- vector(mode = \"character\", length = length(records))\n# id_v <- vector(mode = \"character\", length = length(records))\n# # 2) \n# for(i in seq_along(records)) {\n#  # extract ALL identifier LIST LIST \n#   id_l[[i]] <- records[[i]][[\"header\"]][[\"identifier\"]]\n#   # transform list in vector\n#    id_v[[i]] <- unlist(id_l[[i]])\n# }\n# \n# # 3) \n# id_v_t <- tibble::as_tibble_col(id_v, column_name =\"WDR_hd_id\")\n# df_header_identifier <- id_v_t \n```\n:::\n\n\n#### ... (form header) setSpec\n\n::: {.cell}\n\n```{.r .cell-code}\n# # 0) set variables \n# meta_item <- \"setSpec\"\n# l <- records\n# \n# # 1) Prepare empty output \n# item_l <- list(mode = \"character\", length = length(l))\n# item_v <- vector(mode = \"character\", length = length(l))\n# \n# # 2) ET loop \n# for(i in seq_along(l)) {\n#  # extract ALL setSpec LIST LIST \n#   item_l[[i]] <- l[[i]][[\"header\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WDR_hd_\", meta_item)\n# \n# # 4) make it a tibble   \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# \n# # 5) rename result df \n# # assign(\"new.name\",old.name)\n# assign(paste0(\"df_header_\", meta_item),item_v_t)\n# \n# df_header_setSpec <- item_v_t # non so se serve a qlc \n```\n:::\n\n\n### Parsing xml ONE INDICATOR AT A TIME (metadata)  \n \n+ here I am going to list one level up `records[[\"WRD_1\"]][[\"metadata\"]][[\"dc\"]][[\"item]]`\n+ Problem: multiple repetition of some \"items\"   \n\n#### ... (form metadata) title\n\n::: {.cell}\n\n```{.r .cell-code}\n# # EG all title(s)\n# # records[[\"WRD_1\"]][[\"metadata\"]][[\"dc\"]][[\"title\"]]\n# \n# # 1) Prepare empty ouppt \n# item_l <- list(mode = \"character\", length = length(records))\n# item_v <- vector(mode = \"character\", length = length(records))\n# # 2) \n# for(i in seq_along(records)) {\n#  # extract ALL identifier LIST LIST \n#   item_l[[i]] <- records[[i]][[\"metadata\"]][[\"dc\"]][[\"title\"]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# column_name <- paste0(\"WRD_mt_\", \"title\")  \n# \n# # 3) \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# df_meta_title <- item_v_t \n```\n:::\n\n\n#### ... (form metadata) creator\n\n::: {.cell}\n\n```{.r .cell-code}\n# # EG all creator(s)\n# # records[[\"WRD_1\"]][[\"metadata\"]][[\"dc\"]][[\"creator\"]]\n# \n# # 0) choose metat_item\n# meta_item <- \"creator\"\n# \n# # 1) Prepare empty ouppt \n# item_l <- list(mode = \"character\", length = length(records))\n# item_v <- vector(mode = \"character\", length = length(records))\n# # 2) \n# for(i in seq_along(records)) {\n#  # extract ALL identifier LIST LIST \n#   item_l[[i]] <- records[[i]][[\"metadata\"]][[\"dc\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WRD_mt_\", meta_item)\n# \n# # 3) \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# df_meta_creator<- item_v_t \n```\n:::\n\n\n#### ... (form metadata) identifier\n\n::: {.cell}\n\n```{.r .cell-code}\n#  # 0) set variables \n# meta_item <- \"identifier\"\n# l <- records\n# \n# # 1) Prepare empty output \n# item_l <- list(mode = \"character\", length = length(l))\n# item_l\n# item_v <- vector(mode = \"character\", length = length(l))\n# item_v\n# # 2) ET loop \n# for(i in seq_along(l)) {\n#  # extract ALL identifier LIST LIST \n#   item_l[[i]] <- l[[i]][[\"metadata\"]][[\"dc\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WRD_mt_\", meta_item)\n# \n# # 4) make it a tibble   \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# \n# # 5) rename result df \n# # assign(\"new.name\",old.name)\n# # assign(paste0(\"df_meta_\", meta_item),item_v_t)\n# df_meta_identifier <- item_v_t\n```\n:::\n\n\n#### ... (form metadata) description \n\n::: {.cell}\n\n```{.r .cell-code}\n#  # 0) set variables \n# meta_item <- \"description\"\n# l <- records\n# \n# # 1) Prepare empty output \n# item_l <- list(mode = \"character\", length = length(l))\n# item_l\n# item_v <- vector(mode = \"character\", length = length(l))\n# item_v\n# # 2) ET loop \n# for(i in seq_along(l)) {\n#  # extract ALL description LIST LIST \n#   item_l[[i]] <- l[[i]][[\"metadata\"]][[\"dc\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WRD_mt_\", meta_item)\n# \n# # 4) make it a tibble   \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# \n# # 5) rename result df \n# # assign(\"new.name\",old.name)\n# assign(paste0(\"df_meta_\", meta_item),item_v_t)\n```\n:::\n\n\n#### ... (form metadata) date \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  # 0) set variables \n# meta_item <- \"date\"\n# l <- records\n# \n# # 1) Prepare empty output \n# item_l <- list(mode = \"character\", length = length(l))\n# item_l\n# item_v <- vector(mode = \"character\", length = length(l))\n# item_v\n# # 2) ET loop \n# for(i in seq_along(l)) {\n#  # extract ALL date LIST LIST \n#   item_l[[i]] <- l[[i]][[\"metadata\"]][[\"dc\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WRD_mt_\", meta_item)\n# \n# # 4) make it a tibble   \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# \n# # 5) rename result df \n# # assign(\"new.name\",old.name)\n# assign(paste0(\"df_meta_\", meta_item),item_v_t)\n```\n:::\n\n\n#### ... (form metadata) subject \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  # 0) set variables \n# meta_item <- \"subject\"\n# l <- records\n# \n# # 1) Prepare empty output \n# item_l <- list(mode = \"character\", length = length(l))\n# item_l\n# item_v <- vector(mode = \"character\", length = length(l))\n# item_v\n# # 2) ET loop \n# for(i in seq_along(l)) {\n#  # extract ALL subject LIST LIST \n#   item_l[[i]] <- l[[i]][[\"metadata\"]][[\"dc\"]][[meta_item]]\n#   # transform list in vector\n#    item_v[[i]] <- unlist(item_l[[i]])\n# }\n# # 3) set column name \n# column_name <- paste0(\"WRD_mt_\", meta_item)\n# \n# # 4) make it a tibble   \n# item_v_t <- as_tibble_col(item_v, column_name =column_name)\n# \n# # 5) rename result df \n# # assign(\"new.name\",old.name)\n# assign(paste0(\"df_meta_\", meta_item),item_v_t)\n```\n:::\n\n\n### same but as FUNCTION -> YEP!!!!!!!  \n\n####... ALL from header (func)\n\n::: {.cell}\n\n```{.r .cell-code}\n# ---------- FUNCTION to create a column of Titles --> DOES NOT Work! \n# source(here::here (\"R\", \"turn_list_to_tibble.R\") )\n\n# ------------- USE FUNCTION  (called INSIDE THE `assign`)\n## 1) input: header --> identifier\nlist <- records\nitem_name <- \"identifier\"\nwhere <- \"header\" # or \"header\"\n\ndf_name <- paste(\"col\", item_name, sep = \"_\")\n\n## function call (that changes the name of output on the fly )\nassign(df_name, value = turn_list_to_tibble(list, where, item_name ))\n\n## 2) input: header --> setSpec\nlist <- records\nitem_name <- \"setSpec\"\nwhere <- \"header\" # or \"header\"\n\ndf_name <- paste(\"col\", item_name, sep = \"_\")\n\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col\", item_name, sep = \"_\")\nassign(df_name, value = df)\n```\n:::\n\n\n####... ALL from meta (func)\n\n::: {.cell}\n\n```{.r .cell-code}\n## ------- --------- 1) input: meta --> identifier\nlist <- records\nitem_name <- \"identifier\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n\n## --------- 2) input: meta --> title\nlist <- records\nitem_name <- \"title\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n\n## --------- 3) input: meta --> date\nlist <- records\nitem_name <- \"date\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n\n## --------- 4) input: meta --> creator\nlist <- records\nitem_name <- \"creator\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n\n## --------- 5) input: meta --> subject\nlist <- records\nitem_name <- \"subject\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n\n## --------- 6)  input: meta --> description\nlist <- records\nitem_name <- \"description\"\nwhere <- \"meta\" # or \"meta\"\n## function call (that changes the name of output on the fly )\ndf<- turn_list_to_tibble(list, where, item_name )\n# rename ouptut\ndf_name <- paste(\"col_m\", item_name, sep = \"_\")\nassign(df_name, value = df)\n```\n:::\n\n\n\n#### ... bind ALL - ALL cols into 1 tibble \n\n::: {.cell}\n\n```{.r .cell-code}\nlist_col  <-  ls(pattern =  '^col_', all.names = TRUE)\nlist_col\n cat(noquote(list_col) )\ndf_metadata <- bind_cols(col_identifier,\n                          col_m_identifier,\n                          col_m_title,\n                          col_m_date,\n                          col_m_creator,\n                          col_m_subject,\n                          col_m_description,\n                          col_setSpec, .name_repair = \"unique\"\n                          ) %>% \n  janitor::clean_names()\n```\n:::\n\n\n# save in data/derived_data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(df_metadata)\ndataDir <- fs::path_abs(here::here(\"data\",\"raw_data\"))\nfileName <- \"/WDR.rds\"\nDir_File <- paste0(dataDir, fileName)\nwrite_rds(x = df_metadata, file = Dir_File)\n```\n:::\n\n\n\n# Subject / keywords problem \n\nFollowing [SO Rsponse](https://stackoverflow.com/questions/48476663/extract-text-from-xml-but-file-has-duplicated-node-names/48477966#48477966)\n\n---- DONT RUN ----- \n\n::: {.cell}\n\n```{.r .cell-code}\nxml_find_all(doc, \".//ArchivedIncident\") %>% # iterate over each incident\n  map_df(~{\n    set_names(\n      xml_find_all(.x, \".//value/value\") %>% xml_text(), # get entry values\n      xml_find_all(.x, \".//key\") %>% xml_text()          # get entry keys (column names)\n    ) %>% \n      as.list() %>%                                      # turn named vector to list\n      flatten_df() %>%                                   # and list to df\n      mutate(ID = xml_attr(.x, \"ID\"))                    # add id\n  }) %>%\n  type_convert() %>% # let R convert the values for you\n  select(ID, everything()) # get it in the order you likely want\n## # A tibble: 2 x 5\n##      ID TEST1 TEST2 TEST3 TEST4\n##   <int> <chr> <int> <chr> <chr>\n## 1   100  <NA>    12     A  <NA>\n## 2   101  BLAH    NA  <NA>  <NA>\n\n# ---- my try \nchild <-  xml_child(response, 3) \n\nxml_find_all(child, \".//record\") %>% # iterate over each incident\n  map_df(~{\n    set_names(\n      xml_find_all(.x, \".//subject/subject\") %>% xml_text(), # get entry values\n      xml_find_all(.x, \".//metadata\") %>% xml_text()          # get entry keys (column names)\n    ) %>% \n      as.list() %>%                                      # turn named vector to list\n      flatten_df() %>%                                   # and list to df\n      mutate(ID = xml_attr(.x, \"ID\"))                    # add id\n  }) %>%\n  type_convert() %>% # let R convert the values for you\n  select(ID, everything()) # get it in the order you likely want\n```\n:::\n\n\n### Here I see keywords \n\n2022:  https://openknowledge.worldbank.org/handle/10986/36883?show=full\n\noai:openknowledge.worldbank.org:10986/2586\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read WRD metadata\nWDR <- readr::read_rds(here::here(\"data\", \"raw_data\", \"WDR.rds\" ))\n\n\nWDR <- WDR  %>% \n   # Extract only the portion of string AFTER the backslash {/}\n   mutate(id =  stringr::str_extract(doc_mt_identifier_1, \"[^/]+$\") ) %>% \n   dplyr::relocate(id, .before = doc_mt_identifier_1) %>% \n   mutate(url_keys = paste0(\"https://openknowledge.worldbank.org/handle/10986/\", id , \"?show=full\") )%>% \n   dplyr::relocate(url_keys, .before =  doc_mt_identifier_1)\n\nWDR$id[1] \nWDR$url_keys[1] \n  \nWDR$id[45] \n   \nfor (i in 1:45){\n     print (WDR$url_keys[i] )\n   }\n```\n:::\n\n\n# REVIEW --- \n### Go back and try to extract dates & keywords \n\n# REVIEW --- \n\n## 1. World Bank Projects & Operations:\n\n---- DONT RUN ----- \n\n\n\n  \n\n# Wrangling the text \nFollowing: [@kaye_ella_2019; @robinson_words_2017]\n\n\n## Tokenization \n\n* A _token_ is a meaningful unit of text, such as a word, that we are interested in using for analysis\n\n* bigrams \n\n# connections \n\nFollowing the example of [David Robinson on HN titles](http://varianceexplained.org/r/hn-trends/)\n  \n# Data sources: \n\n1. World Bank Projects & Operations: https://datacatalog.worldbank.org/search/dataset/0037800 \n https://datacatalog.worldbank.org/search/dataset/0037800/World-Bank-Projects---Operations\n\n  + Accessibility Classification: **public** under [Creative Commons Attribution 4.0](https://datacatalog.worldbank.org/public-licenses?fragment=cc)\n\n2. World Bank - World Development Reports\n\n  + Accessibility Classification:\n\n# Acknowledgements \n\n+ [Computing for Social Science Course](https://cfss.uchicago.edu/syllabus/getting-data-from-the-web-api-access/)\n+ [Stephanie Tran](https://github.com/transteph/world-bank-document-scraping) project who created the function `R/f_scrape_WB-OKR.R` \n+ [Renu Khandelwal](https://medium.com/geekculture/reading-xml-files-in-r-3122c3a2a8d9) tutorial \n\n\n\n\n\n\n\n### ----------------------------------------------------------------------------\n\n# Reference Tutorials\n\n[@robinson_1_2022]\n[@ldal_tutorials_2022]\n[@edureka!2019]\n\n \n[David Robinson on HN titles](http://varianceexplained.org/r/hn-trends/)\n\n[Benjamin Soltoff: Computing 4 Social Sciences - API](https://cfss.uchicago.edu/syllabus/getting-data-from-the-web-api-access/)\n\n[Benjamin Soltoff: Computing 4 Social Sciences - text analysis](https://cfss.uchicago.edu/syllabus/text-analysis-fundamentals-and-sentiment-analysis/)\n\n[Ben Schmidt Book Humanities Crurse](https://hdf.benschmidt.org/R/) [Ben Schmidt Book Humanities](http://benschmidt.org/HDA/texts-as-data.html)\n\n[tidyTuesday cast on tidytext](https://github.com/dgrtwo/data-screencasts/tree/master/screencast-annotations)\n\n1.  ✔️ [MEDIUM articles: common words, pairwise correlations - 2018-12-04](https://www.youtube.com/watch?v=C69QyycHsgE)\n2.  [TidyTuesday Tweets - 2019-01-07](https://www.youtube.com/watch?v=KE9ItC3doEU)\n3.  [Wine Ratings - 2019-05-31](https://www.youtube.com/watch?v=AQzZNIyjyWM) Lasso regression \\| sentiment lexicon,\n4.  [Simpsons Guest Stars 2019-08-30](https://www.youtube.com/watch?v=EYuuAGDeGrQ) geom_histogram\n5.  [Horror Movies 2019-10-22](https://www.youtube.com/watch?v=yFRSTlk3kRQ) explaining glmnet package \\| Lasso regression\n6.  [The Office 2020-03-16](https://www.youtube.com/watch?v=_IvAubTDQME) geom_text_repel from ggrepel \\| glmnet package to run a cross-validated LASSO regression\n7.  [Animal Crossing 2020-05-05](https://www.youtube.com/watch?v=Xt7ACiedRRI) Using geom_line and geom_point to graph ratings over time \\| geom_text to visualize what words are associated with positive/negative reviews \\|topic modelling\n",
    "supporting": [
      "00_text_data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}